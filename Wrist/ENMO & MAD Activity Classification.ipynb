{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cd67d3fd-2d48-4904-aa64-b6d7c3b1f657",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import os\n",
    "import time\n",
    "import datetime\n",
    "from sklearn.metrics import f1_score, roc_auc_score, precision_score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "472e0394-a0bf-4238-9505-cd84118352c1",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Paths to data\n",
    "wrist_dir = \"dir\"\n",
    "mapped_dir = \"Outputs/Lower Back Predictions Mapped To Wrist\"\n",
    "\n",
    "# List of participants\n",
    "subjects = os.listdir(mapped_dir)\n",
    "subjects = [subject for subject in subjects if subject not in ['.ipynb_checkpoints']]\n",
    "\n",
    "# Columns to load\n",
    "wrist_columns_to_load = ['accel_x', 'accel_y', 'accel_z']\n",
    "mapped_columns_to_load = ['index', 'accel_x', 'accel_y', 'accel_z', 'lower_back_mapped_value']\n",
    "\n",
    "# Maximum rows to process per participant\n",
    "max_rows_per_participant = 70_000_000\n",
    "\n",
    "# Initialize empty list to store subject-specific evaluation metrics\n",
    "subject_eval_scores = []\n",
    "\n",
    "# Initialized counters for true positives, false positives, and false negatives for ENMO and MAD\n",
    "tp_enmo = 0\n",
    "fp_enmo = 0\n",
    "fn_enmo = 0\n",
    "\n",
    "tp_mad = 0\n",
    "fp_mad = 0\n",
    "fn_mad = 0\n",
    "\n",
    "# Generate a timestamp for outputs\n",
    "timestamp = datetime.datetime.now().strftime(\"%Y-%m-%d_%H-%M-%S\")\n",
    "\n",
    "# Loop through each participant\n",
    "for subject in subjects:\n",
    "    print(f\"Processing subject: {subject}\")\n",
    "    \n",
    "    # Start timer for the subject\n",
    "    subject_start_time = time.time()\n",
    "    \n",
    "    df_loop = []\n",
    "\n",
    "    # Load mapped signal data\n",
    "    mapped_signal_path = os.path.join(mapped_dir, subject, 'wrist_lower_back_df.csv')\n",
    "    mapped_pd = pd.read_csv(mapped_signal_path, usecols=mapped_columns_to_load)\n",
    "    \n",
    "    # Rename 'lower_back_mapped_value' to 'label'\n",
    "    mapped_pd.rename(columns={'lower_back_mapped_value': 'label'}, inplace=True)\n",
    "    \n",
    "    # Convert accelerometer values to float32\n",
    "    mapped_pd[['accel_x', 'accel_y', 'accel_z']] = mapped_pd[['accel_x', 'accel_y', 'accel_z']].astype('float32')\n",
    "    \n",
    "    # Store mapped indices in a set for fast lookups\n",
    "    mapped_indices_set = set(mapped_pd['index'])\n",
    "    \n",
    "    # Load entire wrist signal data\n",
    "    whole_signal_path = os.path.join(wrist_dir, subject, 'combined_ax6_df.csv')\n",
    "\n",
    "    chunk_size = 1_000_000  # Chunk size\n",
    "    rows_read = 0  # Track the number of rows read\n",
    "    \n",
    "    processed_chunks = []\n",
    "\n",
    "    for chunk_idx, chunk in enumerate(pd.read_csv(whole_signal_path, usecols=wrist_columns_to_load, chunksize=chunk_size)):\n",
    "        # Start timer for the chunk\n",
    "        chunk_start_time = time.time()\n",
    "\n",
    "        # Break the loop if max rows are reached\n",
    "        if rows_read >= max_rows_per_participant:\n",
    "            print(f\"Reached max rows ({max_rows_per_participant}) for participant {subject}.\")\n",
    "            break\n",
    "        \n",
    "        # Create the `index` column for whole signal data\n",
    "        chunk.reset_index(inplace=True)\n",
    "\n",
    "        # Drop rows where accelerometer values are NaN\n",
    "        chunk = chunk.dropna(subset=['accel_x', 'accel_y', 'accel_z']).copy()\n",
    "\n",
    "        # Filter out rows in chunk that have an index present in mapped_pd\n",
    "        chunk = chunk[~chunk['index'].isin(mapped_indices_set)]\n",
    "        \n",
    "        # Convert accelerometer values to float32\n",
    "        chunk.loc[:, ['accel_x', 'accel_y', 'accel_z']] = chunk[['accel_x', 'accel_y', 'accel_z']].astype('float32')\n",
    "            \n",
    "        # Assign label 0 for non-mapped data\n",
    "        chunk.loc[:, 'label'] = 0\n",
    "        \n",
    "        # Reorder columns to match mapped_df\n",
    "        chunk = chunk[['index', 'accel_x', 'accel_y', 'accel_z', 'label']]\n",
    "        \n",
    "        # Add chunk to the processed list\n",
    "        processed_chunks.append(chunk)\n",
    "        \n",
    "        # Update the row count\n",
    "        rows_read += len(chunk)\n",
    "    \n",
    "    # Combine all chunks and mapped data into a single DataFrame\n",
    "    df_loop = pd.concat([mapped_pd] + processed_chunks, ignore_index=True)\n",
    "    \n",
    "    # Calculate ENMO\n",
    "    df_loop['ENMO'] = np.sqrt(df_loop['accel_x']**2 + df_loop['accel_y']**2 + df_loop['accel_z']**2) - 1\n",
    "    df_loop['ENMO'] = df_loop['ENMO'].clip(lower=0)\n",
    "    \n",
    "    # Calculate MAD\n",
    "    df_loop['MAD_l2norm'] = df_loop['ENMO'] + 1\n",
    "    df_loop['MAD_window_mean'] = df_loop['MAD_l2norm'].rolling(window=500).mean()\n",
    "    df_loop['MAD_abs'] = (df_loop['MAD_l2norm'] - df_loop['MAD_window_mean']).abs()\n",
    "    df_loop['ENMO_window'] = df_loop['ENMO'].rolling(window=500).mean()\n",
    "    df_loop['MAD_window'] = df_loop['MAD_abs'].rolling(window=500).mean()\n",
    "    \n",
    "    # Drop unneeded columns\n",
    "    df_loop.drop(columns=['ENMO','MAD_l2norm', 'MAD_window_mean', 'MAD_abs'], inplace=True)\n",
    "\n",
    "    # Filter for rows with valid rolling calculations\n",
    "    df_loop = df_loop.dropna(subset=['ENMO_window', 'MAD_window'])\n",
    "    \n",
    "    # Activity classification - specify thresholds here\n",
    "    df_loop['enmo_label'] = (df_loop['ENMO_window'] > 0.07).astype(int)\n",
    "    df_loop['mad_label'] = (df_loop['MAD_window'] > 0.05).astype(int)\n",
    "\n",
    "    \n",
    "    # Compute true positives, false positives, and false negatives using ENMO\n",
    "    subject_tp_enmo = len(df_loop[(df_loop['label'] == df_loop['enmo_label']) & df_loop['label'] == 1])\n",
    "    subject_fp_enmo = len(df_loop[(df_loop['label'] != df_loop['enmo_label']) & df_loop['label'] == 0])\n",
    "    subject_fn_enmo = len(df_loop[(df_loop['label'] != df_loop['enmo_label']) & df_loop['label'] == 1])\n",
    "    \n",
    "    # Compute true positives, false positives, and false negatives using MAD\n",
    "    subject_tp_mad = len(df_loop[(df_loop['label'] == df_loop['mad_label']) & df_loop['label'] == 1])\n",
    "    subject_fp_mad = len(df_loop[(df_loop['label'] != df_loop['mad_label']) & df_loop['label'] == 0])\n",
    "    subject_fn_mad = len(df_loop[(df_loop['label'] != df_loop['mad_label']) & df_loop['label'] == 1])\n",
    "    \n",
    "    # Calculate precision scores\n",
    "    precision_enmo = subject_tp_enmo / (subject_tp_enmo + subject_fp_enmo) if (subject_tp_enmo + subject_fp_enmo) > 0 else 0\n",
    "    precision_mad = subject_tp_mad / (subject_tp_mad + subject_fp_mad) if (subject_tp_mad + subject_fp_mad) > 0 else 0\n",
    "\n",
    "    \n",
    "    # Calculate F1 scores\n",
    "    try:\n",
    "        f1_enmo = f1_score(df_loop['label'], df_loop['enmo_label'])\n",
    "        f1_mad = f1_score(df_loop['label'], df_loop['mad_label'])\n",
    "    except ValueError:\n",
    "        f1_enmo, f1_mad = None, None\n",
    "        \n",
    "    # Calculate AUROC if there are enough positive and negative samples\n",
    "    try:\n",
    "        auroc_enmo = roc_auc_score(df_loop['label'], df_loop['enmo_label'])\n",
    "        auroc_mad = roc_auc_score(df_loop['label'], df_loop['mad_label'])\n",
    "    except ValueError:\n",
    "        auroc_enmo, auroc_mad = None, None\n",
    "        \n",
    "    # Store subject-level scores\n",
    "    subject_eval_scores.append({\n",
    "        'subject': subject,\n",
    "        'f1_score_enmo': f1_enmo,\n",
    "        'f1_score_mad': f1_mad,\n",
    "        'precision_enmo': precision_enmo,\n",
    "        'precision_mad': precision_mad,\n",
    "        'auroc_enmo': auroc_enmo,\n",
    "        'auroc_mad': auroc_mad\n",
    "    })\n",
    "    \n",
    "    tp_enmo += subject_tp_enmo\n",
    "    fp_enmo += subject_fp_enmo\n",
    "    fn_enmo += subject_fn_enmo\n",
    "\n",
    "    tp_mad += subject_tp_mad\n",
    "    fp_mad += subject_fp_mad\n",
    "    fn_mad += subject_fn_mad\n",
    "    \n",
    "    # End timer for the subject\n",
    "    subject_total_time = time.time() - subject_start_time\n",
    "    print(f\"Finished processing subject {subject} in {subject_total_time:.2f} seconds\")\n",
    "\n",
    "# Save subject-level eval scores to a timestamped CSV\n",
    "subject_eval_scores_df = pd.DataFrame(subject_eval_scores)\n",
    "output_filename = f'Outputs/ENMO & MAD/Timestamped Outputs/subject_eval_scores_{timestamp}.csv'\n",
    "subject_eval_scores_df.to_csv(output_filename, index=False)\n",
    "display(subject_eval_scores_df)\n",
    "\n",
    "# Compute eval scores across all subjects\n",
    "precision_combined_enmo = tp_enmo / (tp_enmo + fp_enmo)\n",
    "recall_combined_enmo = tp_enmo / (tp_enmo + fn_enmo)\n",
    "precision_combined_mad = tp_mad / (tp_mad + fp_mad)\n",
    "recall_combined_mad = tp_mad / (tp_mad + fn_mad)\n",
    "\n",
    "# Print combined Precision scores\n",
    "print(f\"Combined Precision Score ENMO: {precision_combined_enmo}\")\n",
    "print(f\"Combined Precision Score MAD: {precision_combined_mad}\\n\")\n",
    "\n",
    "# Derive overall F1\n",
    "f1_combined_enmo = 2*(precision_combined_enmo * recall_combined_enmo)/(precision_combined_enmo + recall_combined_enmo)\n",
    "f1_combined_mad = 2*(precision_combined_mad * recall_combined_mad)/(precision_combined_mad + recall_combined_mad)\n",
    "\n",
    "# Print combined F1 scores\n",
    "print(f\"Combined F1 Score ENMO: {f1_combined_enmo}\")\n",
    "print(f\"Combined F1 Score MAD: {f1_combined_mad}\\n\")\n",
    "\n",
    "overall_eval_scores_df = pd.DataFrame([{\n",
    "    'f1_score_enmo': f1_combined_enmo,\n",
    "    'f1_score_mad': f1_combined_mad,\n",
    "    'precision_enmo': precision_combined_enmo,\n",
    "    'precision_mad': precision_combined_mad\n",
    "}])\n",
    "\n",
    "# Save overall eval scores to a timestamped CSV\n",
    "overall_output_filename = f'Outputs/ENMO & MAD/Timestamped Outputs/overall_eval_scores_{timestamp}.csv'\n",
    "overall_eval_scores_df.to_csv(overall_output_filename, index=False)\n",
    "display(overall_eval_scores_df)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
