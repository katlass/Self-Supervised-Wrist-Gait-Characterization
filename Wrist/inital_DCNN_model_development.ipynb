{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Objective\n",
    "\n",
    "This notebook implements a deep learning convolutional neural network with transfer learning from models Harnet10 and Harnet30. \n",
    "\n",
    "Author: Kate Lassiter\n",
    "\n",
    "Reference: [source](https://github.com/OxWearables/Oxford_Wearables_Activity_Recognition/blob/master/6_self_supervised_learning/ssl_tutorial.ipynb)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 477,
   "metadata": {},
   "outputs": [],
   "source": [
    "import sys\n",
    "sys.path.append(\"../\")\n",
    "import joblib\n",
    "import os\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from torch.utils.data import DataLoader\n",
    "from tqdm import tqdm\n",
    "from sklearn.model_selection import GroupShuffleSplit\n",
    "from sklearn.preprocessing import LabelEncoder\n",
    "from utils.data import NormalDataset, resize, get_inverse_class_weights\n",
    "from utils.utils import EarlyStopping\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "from sklearn.model_selection import train_test_split"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 643,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(((251, 1000, 3), (251,), (251,)), ((54, 1000, 3), (54,), (54,)), ((54, 1000, 3), (54,), (54,)))\n"
     ]
    }
   ],
   "source": [
    "# Data Tranformations\n",
    "csv_file_path = \"/XXXX.csv\"\n",
    "hip_data = pd.read_csv(csv_file_path)\n",
    "\n",
    "num_rows = hip_data.shape[0] # Add a 'group' field, dividing the dataset into 10 equal parts\n",
    "group_size = num_rows // 10  # Calculate the number of rows per group\n",
    "# Create an array with group labels (1 to 10) repeated for each group size\n",
    "group_labels = np.repeat(np.arange(1, 11), group_size)\n",
    "\n",
    "# If remaining rows due to integer division assign them to last group\n",
    "if len(group_labels) < num_rows:\n",
    "    group_labels = np.concatenate([group_labels, np.full(num_rows - len(group_labels), 10)])\n",
    "hip_data['group'] = group_labels # Assign the group labels \n",
    "\n",
    "X = hip_data[['x', 'y', 'z']].values\n",
    "y = hip_data['annotation'].values\n",
    "groups = hip_data['group'].values\n",
    "\n",
    "# Reshape the data into windows of size X\n",
    "def create_windows(data, labels, groups, window_size):\n",
    "    num_windows = data.shape[0] // window_size\n",
    "    X_windows = data[:num_windows * window_size].reshape(num_windows, window_size, -1)\n",
    "    y_windows = labels[window_size-1:num_windows * window_size:window_size]  # One label per window\n",
    "    group_windows = groups[window_size-1:num_windows * window_size:window_size]  # One group per window\n",
    "    return X_windows, y_windows, group_windows\n",
    "\n",
    "window_size = 1000\n",
    "X_windows, y_windows, group_windows = create_windows(X, y, groups, window_size)\n",
    "\n",
    "# Split the data into train, validation, and test sets\n",
    "x_train, x_temp, y_train, y_temp, group_train, group_temp = train_test_split(\n",
    "    X_windows, y_windows, group_windows, test_size=0.3, random_state=42\n",
    ")\n",
    "x_val, x_test, y_val, y_test, group_val, group_test = train_test_split(\n",
    "    x_temp, y_temp, group_temp, test_size=0.5, random_state=42\n",
    ")\n",
    "# Output shapes:\n",
    "print(((x_train.shape, y_train.shape, group_train.shape),\n",
    "       (x_val.shape, y_val.shape, group_val.shape),\n",
    "       (x_test.shape, y_test.shape, group_test.shape)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 645,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using cache found in /Users/kat/.cache/torch/hub/OxWearables_ssl-wearables_main\n",
      "/Users/kat/.cache/torch/hub/OxWearables_ssl-wearables_main/hubconf.py:15: FutureWarning: You are using `torch.load` with `weights_only=False` (the current default value), which uses the default pickle module implicitly. It is possible to construct malicious pickle data which will execute arbitrary code during unpickling (See https://github.com/pytorch/pytorch/blob/main/SECURITY.md#untrusted-models for more details). In a future release, the default value for `weights_only` will be flipped to `True`. This limits the functions that could be executed during unpickling. Arbitrary objects will no longer be allowed to be loaded via this mode unless they are explicitly allowlisted by the user via `torch.serialization.add_safe_globals`. We recommend you start setting `weights_only=True` for any use case where you don't have full control of the loaded file. Please open an issue on GitHub for any issues related to this experimental feature.\n",
      "  pretrained_dict = torch.load(weight_path, map_location=my_device)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "131 Weights loaded\n",
      "training set sample count : 251\n",
      "validation set sample count : 54\n",
      "test set sample count : 54\n"
     ]
    }
   ],
   "source": [
    "# construct dataloaders\n",
    "train_dataset = NormalDataset(x_train, y_train, group_train, name=\"training\", transform=True)\n",
    "val_dataset = NormalDataset(x_val, y_val, group_val, name=\"validation\")\n",
    "test_dataset = NormalDataset(x_test, y_test, group_test, name=\"test\")\n",
    "train_loader = DataLoader(\n",
    "    train_dataset,\n",
    "    batch_size=128,\n",
    "    shuffle=True,\n",
    "    num_workers=2,\n",
    ")\n",
    "val_loader = DataLoader(\n",
    "    val_dataset,\n",
    "    batch_size=128,\n",
    "    shuffle=False,\n",
    "    num_workers=0,\n",
    ")\n",
    "test_loader = DataLoader(\n",
    "    test_dataset,\n",
    "    batch_size=128,\n",
    "    shuffle=False,\n",
    "    num_workers=0,\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 615,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[tensor([[[ 0.8423,  0.8298,  0.8320,  ...,  0.7434,  0.7612,  0.7713],\n",
      "         [ 0.3924,  0.3924,  0.3924,  ...,  0.3836,  0.3744,  0.3764],\n",
      "         [-0.3874, -0.3874, -0.3874,  ..., -0.6145, -0.6145, -0.6145]],\n",
      "\n",
      "        [[ 0.7674,  0.7674,  0.7674,  ...,  0.7813,  0.7840,  0.7835],\n",
      "         [ 0.0389,  0.0389,  0.0389,  ...,  0.0389,  0.0389,  0.0389],\n",
      "         [-0.6287, -0.6286, -0.6295,  ..., -0.6294, -0.6274, -0.6440]],\n",
      "\n",
      "        [[ 0.7351,  0.7351,  0.7348,  ...,  0.7513,  0.7513,  0.7513],\n",
      "         [ 0.2319,  0.2319,  0.2319,  ...,  0.2819,  0.2798,  0.2801],\n",
      "         [-0.6260, -0.6260, -0.6260,  ..., -0.5935, -0.5954, -0.5807]],\n",
      "\n",
      "        ...,\n",
      "\n",
      "        [[ 0.7511,  0.7511,  0.7511,  ...,  0.7532,  0.7431,  0.7326],\n",
      "         [ 0.3674,  0.3583,  0.3621,  ...,  0.3281,  0.3262,  0.3352],\n",
      "         [-0.5334, -0.5313, -0.5408,  ..., -0.5821, -0.5801, -0.5892]],\n",
      "\n",
      "        [[ 0.8443,  0.8675,  0.9617,  ...,  1.0334,  1.0448,  1.0412],\n",
      "         [-0.2197, -0.2229, -0.2423,  ..., -0.1639, -0.1789, -0.1899],\n",
      "         [ 0.0586,  0.0460,  0.0558,  ..., -0.2249, -0.2625, -0.2707]],\n",
      "\n",
      "        [[ 0.7513,  0.7494,  0.7596,  ...,  0.7513,  0.7513,  0.7513],\n",
      "         [ 0.2240,  0.2340,  0.2319,  ...,  0.2515,  0.2659,  0.2640],\n",
      "         [-0.6204, -0.6083, -0.6104,  ..., -0.6083, -0.6101, -0.6124]]],\n",
      "       dtype=torch.float64), tensor([0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
      "        0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
      "        0, 0, 0, 0, 0, 0]), tensor([ 9,  3,  2,  5,  6,  6,  8,  7,  7, 10,  1,  2,  7,  4,  4,  3,  1,  6,\n",
      "        10,  9,  6,  1,  3,  5, 10,  1,  1,  9,  4,  5,  4,  9,  4,  5,  8,  4,\n",
      "         1,  6,  8,  3,  8,  3,  2,  6,  1,  4, 10,  2,  4,  3,  9, 10, 10,  2])]\n",
      "54 54 54\n"
     ]
    }
   ],
   "source": [
    "for batch in test_loader:\n",
    "    print(batch)\n",
    "    print(len(batch[0]),len(batch[1]),len(batch[2]))\n",
    "    break"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "What follows directly below is from [source]('https://github.com/OxWearables/Oxford_Wearables_Activity_Recognition/blob/master/6_self_supervised_learning/ssl_tutorial.ipynb')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 653,
   "metadata": {},
   "outputs": [],
   "source": [
    "def train(model, train_loader, val_loader, device, weights=None):\n",
    "    \"\"\"\n",
    "    Iterate over the training dataloader and train a pytorch model.\n",
    "    After each epoch, validate model and early stop when validation loss function bottoms out.\n",
    "\n",
    "    Trained model weights will be saved to disk (state_dict.pt).\n",
    "\n",
    "    :param nn.Module model: pytorch model\n",
    "    :param train_loader: training data loader\n",
    "    :param val_loader: validation data loader\n",
    "    :param str device: pytorch map device.\n",
    "    :param weights: training class weights (to enable weighted loss function)\n",
    "    \"\"\"\n",
    "\n",
    "    state_dict = 'state_dict.pt'\n",
    "\n",
    "    # REDUCE THIS IF YOU WANT TO SPEED UP THINGS, E.G. 2\n",
    "    num_epoch = 5\n",
    "\n",
    "    optimizer = torch.optim.Adam(\n",
    "        model.parameters(), lr=0.0001, amsgrad=True\n",
    "    )\n",
    "\n",
    "    if weights:\n",
    "        weights = torch.FloatTensor(weights).to(device)\n",
    "        loss_fn = nn.CrossEntropyLoss(weight=weights)\n",
    "    else:\n",
    "        loss_fn = nn.CrossEntropyLoss()\n",
    "\n",
    "    early_stopping = EarlyStopping(\n",
    "        patience=5, path=state_dict, verbose=True\n",
    "    )\n",
    "\n",
    "    for epoch in range(num_epoch):\n",
    "        model.train()\n",
    "        train_losses = []\n",
    "        train_acces = []\n",
    "        for i, (x, y, _) in enumerate(tqdm(train_loader)):\n",
    "            x.requires_grad_(True)\n",
    "            x = x.to(device, dtype=torch.float)\n",
    "            true_y = y.to(device, dtype=torch.long)\n",
    "            optimizer.zero_grad()\n",
    "            logits = model(x)\n",
    "            loss = loss_fn(logits, true_y)\n",
    "            loss.backward()\n",
    "            optimizer.step()\n",
    "\n",
    "            pred_y = torch.argmax(logits, dim=1)\n",
    "            train_acc = torch.sum(pred_y == true_y)\n",
    "            train_acc = train_acc / (pred_y.size()[0])\n",
    "\n",
    "            train_losses.append(loss.cpu().detach())\n",
    "            train_acces.append(train_acc.cpu().detach())\n",
    "\n",
    "        val_loss, val_acc = _validate_model(model, val_loader, device, loss_fn)\n",
    "\n",
    "        epoch_len = len(str(num_epoch))\n",
    "        print_msg = (\n",
    "            f\"[{epoch:>{epoch_len}}/{num_epoch:>{epoch_len}}] | \"\n",
    "            + f\"train_loss: {np.mean(train_losses):.3f} | \"\n",
    "            + f\"train_acc: {np.mean(train_acces):.3f} | \"\n",
    "            + f\"val_loss: {val_loss:.3f} | \"\n",
    "            + f\"val_acc: {val_acc:.2f}\"\n",
    "        )\n",
    "\n",
    "        early_stopping(val_loss, model)\n",
    "        print(print_msg)\n",
    "\n",
    "        if early_stopping.early_stop:\n",
    "            print('Early stopping')\n",
    "            print(f'SSLNet weights saved to {state_dict}')\n",
    "            break\n",
    "\n",
    "\n",
    "def _validate_model(model, val_loader, device, loss_fn):\n",
    "    \"\"\" Iterate over a validation data loader and return mean model loss and accuracy. \"\"\"\n",
    "    model.eval()\n",
    "    losses = []\n",
    "    acces = []\n",
    "    for i, (x, y, _) in enumerate(val_loader):\n",
    "        with torch.inference_mode():\n",
    "            x = x.to(device, dtype=torch.float)\n",
    "            true_y = y.to(device, dtype=torch.long)\n",
    "\n",
    "            logits = model(x)\n",
    "            loss = loss_fn(logits, true_y)\n",
    "\n",
    "            pred_y = torch.argmax(logits, dim=1)\n",
    "\n",
    "            val_acc = torch.sum(pred_y == true_y)\n",
    "            val_acc = val_acc / (list(pred_y.size())[0])\n",
    "\n",
    "            losses.append(loss.cpu().detach())\n",
    "            acces.append(val_acc.cpu().detach())\n",
    "    losses = np.array(losses)\n",
    "    acces = np.array(acces)\n",
    "    return np.mean(losses), np.mean(acces)\n",
    "\n",
    "\n",
    "def predict(model, data_loader, device):\n",
    "    \"\"\"\n",
    "    Iterate over the dataloader and do inference with a pytorch model.\n",
    "\n",
    "    :param nn.Module model: pytorch Module\n",
    "    :param data_loader: pytorch dataloader\n",
    "    :param str device: pytorch map device\n",
    "    :return: true labels, model predictions, pids\n",
    "    :rtype: (np.ndarray, np.ndarray, np.ndarray)\n",
    "    \"\"\"\n",
    "\n",
    "    from tqdm import tqdm\n",
    "\n",
    "    predictions_list = []\n",
    "    true_list = []\n",
    "    pid_list = []\n",
    "    model.eval()\n",
    "\n",
    "    for i, (x, y, pid) in enumerate(tqdm(data_loader)):\n",
    "        with torch.inference_mode():\n",
    "            x = x.to(device, dtype=torch.float)\n",
    "            logits = model(x)\n",
    "            true_list.append(y)\n",
    "            pred_y = torch.argmax(logits, dim=1)\n",
    "            predictions_list.append(pred_y.cpu())\n",
    "            pid_list.extend(pid)\n",
    "    true_list = torch.cat(true_list)\n",
    "    predictions_list = torch.cat(predictions_list)\n",
    "\n",
    "    return (\n",
    "        torch.flatten(true_list).numpy(),\n",
    "        torch.flatten(predictions_list).numpy(),\n",
    "        np.array(pid_list),\n",
    "    )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 543,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using cache found in /Users/kat/.cache/torch/hub/OxWearables_ssl-wearables_main\n",
      "/Users/kat/.cache/torch/hub/OxWearables_ssl-wearables_main/hubconf.py:15: FutureWarning: You are using `torch.load` with `weights_only=False` (the current default value), which uses the default pickle module implicitly. It is possible to construct malicious pickle data which will execute arbitrary code during unpickling (See https://github.com/pytorch/pytorch/blob/main/SECURITY.md#untrusted-models for more details). In a future release, the default value for `weights_only` will be flipped to `True`. This limits the functions that could be executed during unpickling. Arbitrary objects will no longer be allowed to be loaded via this mode unless they are explicitly allowlisted by the user via `torch.serialization.add_safe_globals`. We recommend you start setting `weights_only=True` for any use case where you don't have full control of the loaded file. Please open an issue on GitHub for any issues related to this experimental feature.\n",
      "  pretrained_dict = torch.load(weight_path, map_location=my_device)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "131 Weights loaded\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "Resnet(\n",
       "  (feature_extractor): Sequential(\n",
       "    (layer1): Sequential(\n",
       "      (0): Conv1d(3, 64, kernel_size=(5,), stride=(1,), padding=(2,), bias=False, padding_mode=circular)\n",
       "      (1): ResBlock(\n",
       "        (bn1): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (bn2): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (conv1): Conv1d(64, 64, kernel_size=(5,), stride=(1,), padding=(2,), bias=False, padding_mode=circular)\n",
       "        (conv2): Conv1d(64, 64, kernel_size=(5,), stride=(1,), padding=(2,), bias=False, padding_mode=circular)\n",
       "        (relu): ReLU(inplace=True)\n",
       "      )\n",
       "      (2): ResBlock(\n",
       "        (bn1): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (bn2): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (conv1): Conv1d(64, 64, kernel_size=(5,), stride=(1,), padding=(2,), bias=False, padding_mode=circular)\n",
       "        (conv2): Conv1d(64, 64, kernel_size=(5,), stride=(1,), padding=(2,), bias=False, padding_mode=circular)\n",
       "        (relu): ReLU(inplace=True)\n",
       "      )\n",
       "      (3): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (4): ReLU(inplace=True)\n",
       "      (5): Downsample()\n",
       "    )\n",
       "    (layer2): Sequential(\n",
       "      (0): Conv1d(64, 128, kernel_size=(5,), stride=(1,), padding=(2,), bias=False, padding_mode=circular)\n",
       "      (1): ResBlock(\n",
       "        (bn1): BatchNorm1d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (bn2): BatchNorm1d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (conv1): Conv1d(128, 128, kernel_size=(5,), stride=(1,), padding=(2,), bias=False, padding_mode=circular)\n",
       "        (conv2): Conv1d(128, 128, kernel_size=(5,), stride=(1,), padding=(2,), bias=False, padding_mode=circular)\n",
       "        (relu): ReLU(inplace=True)\n",
       "      )\n",
       "      (2): ResBlock(\n",
       "        (bn1): BatchNorm1d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (bn2): BatchNorm1d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (conv1): Conv1d(128, 128, kernel_size=(5,), stride=(1,), padding=(2,), bias=False, padding_mode=circular)\n",
       "        (conv2): Conv1d(128, 128, kernel_size=(5,), stride=(1,), padding=(2,), bias=False, padding_mode=circular)\n",
       "        (relu): ReLU(inplace=True)\n",
       "      )\n",
       "      (3): BatchNorm1d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (4): ReLU(inplace=True)\n",
       "      (5): Downsample()\n",
       "    )\n",
       "    (layer3): Sequential(\n",
       "      (0): Conv1d(128, 256, kernel_size=(5,), stride=(1,), padding=(2,), bias=False, padding_mode=circular)\n",
       "      (1): ResBlock(\n",
       "        (bn1): BatchNorm1d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (bn2): BatchNorm1d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (conv1): Conv1d(256, 256, kernel_size=(5,), stride=(1,), padding=(2,), bias=False, padding_mode=circular)\n",
       "        (conv2): Conv1d(256, 256, kernel_size=(5,), stride=(1,), padding=(2,), bias=False, padding_mode=circular)\n",
       "        (relu): ReLU(inplace=True)\n",
       "      )\n",
       "      (2): ResBlock(\n",
       "        (bn1): BatchNorm1d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (bn2): BatchNorm1d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (conv1): Conv1d(256, 256, kernel_size=(5,), stride=(1,), padding=(2,), bias=False, padding_mode=circular)\n",
       "        (conv2): Conv1d(256, 256, kernel_size=(5,), stride=(1,), padding=(2,), bias=False, padding_mode=circular)\n",
       "        (relu): ReLU(inplace=True)\n",
       "      )\n",
       "      (3): BatchNorm1d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (4): ReLU(inplace=True)\n",
       "      (5): Downsample()\n",
       "    )\n",
       "    (layer4): Sequential(\n",
       "      (0): Conv1d(256, 512, kernel_size=(5,), stride=(1,), padding=(2,), bias=False, padding_mode=circular)\n",
       "      (1): ResBlock(\n",
       "        (bn1): BatchNorm1d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (bn2): BatchNorm1d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (conv1): Conv1d(512, 512, kernel_size=(5,), stride=(1,), padding=(2,), bias=False, padding_mode=circular)\n",
       "        (conv2): Conv1d(512, 512, kernel_size=(5,), stride=(1,), padding=(2,), bias=False, padding_mode=circular)\n",
       "        (relu): ReLU(inplace=True)\n",
       "      )\n",
       "      (2): ResBlock(\n",
       "        (bn1): BatchNorm1d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (bn2): BatchNorm1d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (conv1): Conv1d(512, 512, kernel_size=(5,), stride=(1,), padding=(2,), bias=False, padding_mode=circular)\n",
       "        (conv2): Conv1d(512, 512, kernel_size=(5,), stride=(1,), padding=(2,), bias=False, padding_mode=circular)\n",
       "        (relu): ReLU(inplace=True)\n",
       "      )\n",
       "      (3): BatchNorm1d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (4): ReLU(inplace=True)\n",
       "      (5): Downsample()\n",
       "    )\n",
       "    (layer5): Sequential(\n",
       "      (0): Conv1d(512, 1024, kernel_size=(5,), stride=(1,), padding=(2,), bias=False, padding_mode=circular)\n",
       "      (1): BatchNorm1d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (2): ReLU(inplace=True)\n",
       "      (3): Downsample()\n",
       "    )\n",
       "  )\n",
       "  (classifier): EvaClassifier(\n",
       "    (linear1): Linear(in_features=1024, out_features=512, bias=True)\n",
       "    (linear2): Linear(in_features=512, out_features=6, bias=True)\n",
       "  )\n",
       ")"
      ]
     },
     "execution_count": 543,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Load the pretrained model\n",
    "os.environ['GITHUB_TOKEN'] = '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'\n",
    "repo = 'OxWearables/ssl-wearables'\n",
    "sslnet: nn.Module = torch.hub.load(repo, 'harnet30', trust_repo=True, class_num=2, pretrained=True, weights_only=False)\n",
    "sslnet.to(device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 655,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Inverse class weights: \n",
      "[1.004, 251.0]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  0%|                                                     | 0/2 [00:00<?, ?it/s]python(52872) MallocStackLogging: can't turn off malloc stack logging because it was not enabled.\n",
      "python(52873) MallocStackLogging: can't turn off malloc stack logging because it was not enabled.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "here torch.Size([128, 3, 1000])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 50%|██████████████████████▌                      | 1/2 [00:11<00:11, 11.44s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "here torch.Size([123, 3, 1000])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|█████████████████████████████████████████████| 2/2 [00:21<00:00, 10.77s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Validation loss decreased (inf --> 0.000164). Saving model ...\n",
      "[0/5] | train_loss: 0.153 | train_acc: 0.957 | val_loss: 0.000 | val_acc: 1.00\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  0%|                                                     | 0/2 [00:00<?, ?it/s]python(52889) MallocStackLogging: can't turn off malloc stack logging because it was not enabled.\n",
      "python(52890) MallocStackLogging: can't turn off malloc stack logging because it was not enabled.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "here torch.Size([128, 3, 1000])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 50%|██████████████████████▌                      | 1/2 [00:11<00:11, 11.68s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "here torch.Size([123, 3, 1000])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|█████████████████████████████████████████████| 2/2 [00:21<00:00, 10.67s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Validation loss decreased (0.000164 --> 0.000005). Saving model ...\n",
      "[1/5] | train_loss: 16.323 | train_acc: 0.996 | val_loss: 0.000 | val_acc: 1.00\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  0%|                                                     | 0/2 [00:00<?, ?it/s]python(52915) MallocStackLogging: can't turn off malloc stack logging because it was not enabled.\n",
      "python(52916) MallocStackLogging: can't turn off malloc stack logging because it was not enabled.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "here torch.Size([128, 3, 1000])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 50%|██████████████████████▌                      | 1/2 [00:10<00:10, 10.99s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "here torch.Size([123, 3, 1000])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|█████████████████████████████████████████████| 2/2 [00:22<00:00, 11.03s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Validation loss decreased (0.000005 --> 0.000000). Saving model ...\n",
      "[2/5] | train_loss: 2.460 | train_acc: 0.996 | val_loss: 0.000 | val_acc: 1.00\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  0%|                                                     | 0/2 [00:00<?, ?it/s]python(52934) MallocStackLogging: can't turn off malloc stack logging because it was not enabled.\n",
      "python(52935) MallocStackLogging: can't turn off malloc stack logging because it was not enabled.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "here torch.Size([128, 3, 1000])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 50%|██████████████████████▌                      | 1/2 [00:16<00:16, 16.94s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "here torch.Size([123, 3, 1000])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|█████████████████████████████████████████████| 2/2 [00:34<00:00, 17.15s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Validation loss decreased (0.000000 --> 0.000000). Saving model ...\n",
      "[3/5] | train_loss: 0.000 | train_acc: 1.000 | val_loss: 0.000 | val_acc: 1.00\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  0%|                                                     | 0/2 [00:00<?, ?it/s]python(52957) MallocStackLogging: can't turn off malloc stack logging because it was not enabled.\n",
      "python(52958) MallocStackLogging: can't turn off malloc stack logging because it was not enabled.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "here torch.Size([128, 3, 1000])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 50%|██████████████████████▌                      | 1/2 [00:18<00:18, 18.21s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "here torch.Size([123, 3, 1000])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|█████████████████████████████████████████████| 2/2 [00:33<00:00, 16.82s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Validation loss decreased (0.000000 --> 0.000000). Saving model ...\n",
      "[4/5] | train_loss: 0.041 | train_acc: 0.988 | val_loss: 0.000 | val_acc: 1.00\n"
     ]
    }
   ],
   "source": [
    "# Train the model. The trained weights will be saved in the file 'state_dict.pt'\n",
    "device=\"cpu\"\n",
    "train(sslnet, train_loader, val_loader, device, get_inverse_class_weights(y_train))\n",
    "#"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 651,
   "metadata": {},
   "outputs": [],
   "source": [
    "# helper function to calculate classification performance scores: precision, recall, F1 and Kappa\n",
    "def classification_scores(y_test, y_test_pred):\n",
    "    import sklearn.metrics as metrics\n",
    "\n",
    "    cohen_kappa = metrics.cohen_kappa_score(y_test, y_test_pred)\n",
    "    precision = metrics.precision_score(\n",
    "        y_test, y_test_pred, average=\"macro\", zero_division=0\n",
    "    )\n",
    "    recall = metrics.recall_score(\n",
    "        y_test, y_test_pred, average=\"macro\", zero_division=0\n",
    "    )\n",
    "    f1 = metrics.f1_score(\n",
    "        y_test, y_test_pred, average=\"macro\", zero_division=0\n",
    "    )\n",
    "\n",
    "    data = {\n",
    "        \"precision\": precision,\n",
    "        \"recall\": recall,\n",
    "        \"f1\": f1,\n",
    "        \"kappa\": cohen_kappa,\n",
    "    }\n",
    "\n",
    "    df = pd.DataFrame(data, index=[0])  # use a dataframe because this prints nicely later\n",
    "\n",
    "    return df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 657,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/var/folders/m6/bmzv652526d9yl3g_l5shcg40000gn/T/ipykernel_44092/1368894285.py:2: FutureWarning: You are using `torch.load` with `weights_only=False` (the current default value), which uses the default pickle module implicitly. It is possible to construct malicious pickle data which will execute arbitrary code during unpickling (See https://github.com/pytorch/pytorch/blob/main/SECURITY.md#untrusted-models for more details). In a future release, the default value for `weights_only` will be flipped to `True`. This limits the functions that could be executed during unpickling. Arbitrary objects will no longer be allowed to be loaded via this mode unless they are explicitly allowlisted by the user via `torch.serialization.add_safe_globals`. We recommend you start setting `weights_only=True` for any use case where you don't have full control of the loaded file. Please open an issue on GitHub for any issues related to this experimental feature.\n",
      "  model_dict = torch.load('state_dict.pt', map_location=device)\n",
      "100%|█████████████████████████████████████████████| 1/1 [00:03<00:00,  3.26s/it]\n"
     ]
    }
   ],
   "source": [
    "# load fine tuned weights (best weights prior to early-stopping) and do inference on the test set\n",
    "model_dict = torch.load('state_dict.pt', map_location=device)\n",
    "sslnet.load_state_dict(model_dict)\n",
    "\n",
    "y_test, y_test_pred, pid_test = predict(sslnet, test_loader, device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 659,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "   precision  recall   f1  kappa\n",
      "0        1.0     1.0  1.0    NaN\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Applications/anaconda3/lib/python3.12/site-packages/sklearn/metrics/_classification.py:386: UserWarning: A single label was found in 'y_true' and 'y_pred'. For the confusion matrix to have the correct shape, use the 'labels' parameter to pass all known labels.\n",
      "  warnings.warn(\n",
      "/Applications/anaconda3/lib/python3.12/site-packages/sklearn/metrics/_classification.py:708: RuntimeWarning: invalid value encountered in scalar divide\n",
      "  k = np.sum(w_mat * confusion) / np.sum(w_mat * expected)\n"
     ]
    }
   ],
   "source": [
    "scores = classification_scores(y_test, y_test_pred)\n",
    "print(scores.round(3))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Harnet30 is offerfitting, exploring Harnet 10\n",
    "My code again below"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'/Users/kat/Oxford_Wearables_Activity_Recognition/6_self_supervised_learning'"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "os.getcwd()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: pynvml in /Applications/anaconda3/lib/python3.12/site-packages (11.5.3)\n"
     ]
    }
   ],
   "source": [
    "!pip install pynvml"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Collecting torch\n",
      "  Downloading torch-2.5.0-cp312-none-macosx_11_0_arm64.whl.metadata (28 kB)\n",
      "Collecting torchvision\n",
      "  Downloading torchvision-0.20.0-cp312-cp312-macosx_11_0_arm64.whl.metadata (6.1 kB)\n",
      "Collecting torchaudio\n",
      "  Downloading torchaudio-2.5.0-cp312-cp312-macosx_11_0_arm64.whl.metadata (6.4 kB)\n",
      "Requirement already satisfied: filelock in /Applications/anaconda3/lib/python3.12/site-packages (from torch) (3.13.1)\n",
      "Requirement already satisfied: typing-extensions>=4.8.0 in /Applications/anaconda3/lib/python3.12/site-packages (from torch) (4.11.0)\n",
      "Requirement already satisfied: networkx in /Applications/anaconda3/lib/python3.12/site-packages (from torch) (3.2.1)\n",
      "Requirement already satisfied: jinja2 in /Applications/anaconda3/lib/python3.12/site-packages (from torch) (3.1.4)\n",
      "Requirement already satisfied: fsspec in /Applications/anaconda3/lib/python3.12/site-packages (from torch) (2024.3.1)\n",
      "Requirement already satisfied: setuptools in /Applications/anaconda3/lib/python3.12/site-packages (from torch) (69.5.1)\n",
      "Collecting sympy==1.13.1 (from torch)\n",
      "  Using cached sympy-1.13.1-py3-none-any.whl.metadata (12 kB)\n",
      "Requirement already satisfied: mpmath<1.4,>=1.1.0 in /Applications/anaconda3/lib/python3.12/site-packages (from sympy==1.13.1->torch) (1.3.0)\n",
      "Requirement already satisfied: numpy in /Applications/anaconda3/lib/python3.12/site-packages (from torchvision) (1.26.4)\n",
      "Requirement already satisfied: pillow!=8.3.*,>=5.3.0 in /Applications/anaconda3/lib/python3.12/site-packages (from torchvision) (10.3.0)\n",
      "Requirement already satisfied: MarkupSafe>=2.0 in /Applications/anaconda3/lib/python3.12/site-packages (from jinja2->torch) (2.1.3)\n",
      "Downloading torch-2.5.0-cp312-none-macosx_11_0_arm64.whl (64.3 MB)\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m64.3/64.3 MB\u001b[0m \u001b[31m52.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m00:01\u001b[0m00:01\u001b[0m\n",
      "\u001b[?25hUsing cached sympy-1.13.1-py3-none-any.whl (6.2 MB)\n",
      "Downloading torchvision-0.20.0-cp312-cp312-macosx_11_0_arm64.whl (1.8 MB)\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m1.8/1.8 MB\u001b[0m \u001b[31m47.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m00:01\u001b[0m\n",
      "\u001b[?25hDownloading torchaudio-2.5.0-cp312-cp312-macosx_11_0_arm64.whl (1.8 MB)\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m1.8/1.8 MB\u001b[0m \u001b[31m40.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0ma \u001b[36m0:00:01\u001b[0m\n",
      "\u001b[?25hInstalling collected packages: sympy, torch, torchvision, torchaudio\n",
      "  Attempting uninstall: sympy\n",
      "    Found existing installation: sympy 1.12\n",
      "    Uninstalling sympy-1.12:\n",
      "      Successfully uninstalled sympy-1.12\n",
      "Successfully installed sympy-1.13.1 torch-2.5.0 torchaudio-2.5.0 torchvision-0.20.0\n"
     ]
    }
   ],
   "source": [
    "!pip install torch torchvision torchaudio     "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Collecting transforms3d\n",
      "  Downloading transforms3d-0.4.2-py3-none-any.whl.metadata (2.8 kB)\n",
      "Requirement already satisfied: numpy>=1.15 in /Applications/anaconda3/lib/python3.12/site-packages (from transforms3d) (1.26.4)\n",
      "Downloading transforms3d-0.4.2-py3-none-any.whl (1.4 MB)\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m1.4/1.4 MB\u001b[0m \u001b[31m5.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0ma \u001b[36m0:00:01\u001b[0m\n",
      "\u001b[?25hInstalling collected packages: transforms3d\n",
      "Successfully installed transforms3d-0.4.2\n"
     ]
    }
   ],
   "source": [
    "!pip install transforms3d"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 255,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using cache found in /Users/kat/.cache/torch/hub/OxWearables_ssl-wearables_main\n",
      "/Users/kat/.cache/torch/hub/OxWearables_ssl-wearables_main/hubconf.py:15: FutureWarning: You are using `torch.load` with `weights_only=False` (the current default value), which uses the default pickle module implicitly. It is possible to construct malicious pickle data which will execute arbitrary code during unpickling (See https://github.com/pytorch/pytorch/blob/main/SECURITY.md#untrusted-models for more details). In a future release, the default value for `weights_only` will be flipped to `True`. This limits the functions that could be executed during unpickling. Arbitrary objects will no longer be allowed to be loaded via this mode unless they are explicitly allowlisted by the user via `torch.serialization.add_safe_globals`. We recommend you start setting `weights_only=True` for any use case where you don't have full control of the loaded file. Please open an issue on GitHub for any issues related to this experimental feature.\n",
      "  pretrained_dict = torch.load(weight_path, map_location=my_device)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "131 Weights loaded\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "tensor([[21.1082, 10.9276]], grad_fn=<AddmmBackward0>)"
      ]
     },
     "execution_count": 255,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Tring harnet10 on subset\n",
    "repo='OxWearables/ssl-wearables'\n",
    "harnet10= torch.hub.load(repo, 'harnet10', class_num=2, pretrained=True)\n",
    "float_tensor = torch.tensor(data[['x','y','z']][0:300].values.T, dtype=torch.float)\n",
    "x=float_tensor.unsqueeze(0)\n",
    "x = torch.FloatTensor(x)\n",
    "harnet10(x)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 259,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Get time chnage metrics\n",
    "def time_params(df):\n",
    "    df['timestamp']=pd.to_datetime(df['timestamp'])\n",
    "    initial_time=pd.Timedelta(seconds=0)\n",
    "    time_chg=(df['timestamp']-df['timestamp'].shift(1)).fillna(initial_time)\n",
    "    time_chg=time_chg.dt.total_seconds() \n",
    "    time_avg=time_chg.mean()  \n",
    "    samp_freq_= 1.0/time_avg  \n",
    "    time_= np.cumsum(time_chg) \n",
    "    return df, samp_freq_,time_,time_avg"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 261,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Store inputs as numpy files\n",
    "data=pd.read_csv(\"/XXXX.csv\")\n",
    "np.save(\"X.npy\", data[['x','y','z']].values)\n",
    "np.save(\"Y.npy\", data['annotation'].values)\n",
    "time=time_params(data)[2].values\n",
    "np.save(\"T.npy\", time)\n",
    "reps=round(len(data)/10)\n",
    "pids=[]\n",
    "for x in range(1,11):\n",
    "    pids+=[x]*reps   \n",
    "pids=pids[:len(data)]\n",
    "np.save(\"pid.npy\", pids)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Custom Data Windowing "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 403,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Reshaped features shape: (35999, 10, 3)\n",
      "Final labels shape: (35999,)\n",
      "Final patient IDs shape: (35999,)\n"
     ]
    }
   ],
   "source": [
    "# Windowing Data\n",
    "np.random.seed(42) \n",
    "features = data[['x', 'y', 'z']].values\n",
    "labels= data['annotation'].values\n",
    "patient_ids = data['patient_id'].values\n",
    "\n",
    "window_size =10\n",
    "num_samples = len(features)//window_size\n",
    "reshaped_features= features[:num_samples*window_size].reshape(num_samples, window_size, 3)\n",
    "reshaped_labels = labels[:num_samples*window_size].reshape(num_samples, window_size)\n",
    "reshaped_patient_ids = patient_ids[:num_samples*window_size].reshape(num_samples, window_size)\n",
    "final_labels= stats.mode(reshaped_labels, axis=1)[0].reshape(-1)\n",
    "final_patient_ids = reshaped_patient_ids[:,0]\n",
    "print(\"Reshaped features shape:\", reshaped_features.shape)\n",
    "print(\"Final labels shape:\", final_labels.shape)\n",
    "print(\"Final patient IDs shape:\", final_patient_ids.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 505,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(((21635, 10, 3), (21635,), (21635,)),\n",
       " ((3593, 10, 3), (3593,), (3593,)),\n",
       " ((3572, 10, 3), (3572,), (21635,)))"
      ]
     },
     "execution_count": 505,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#Tring GroupShuffleSplit\n",
    "reshaped_patient_ids=patient_ids[:num_samples*window_size].reshape(num_samples, window_size)\n",
    "final_patient_ids = reshaped_patient_ids[:,0]\n",
    "\n",
    "splitter = GroupShuffleSplit(n_splits=1, test_size=0.2, train_size=0.6, random_state=42)\n",
    "splitter_val = GroupShuffleSplit(n_splits=1, test_size=0.5, random_state=42)  # To split remaining data into val and test\n",
    "train_idx, temp_idx = next(splitter.split(reshaped_features, final_labels, groups=final_patient_ids))\n",
    "val_idx, test_idx = next(splitter_val.split(reshaped_features[temp_idx], final_labels[temp_idx], groups=final_patient_ids[temp_idx]))\n",
    "\n",
    "x_train, y_train, group_train = reshaped_features[train_idx], final_labels[train_idx], final_patient_ids[train_idx]\n",
    "x_val, y_val, group_val = reshaped_features[val_idx], final_labels[val_idx], final_patient_ids[val_idx]\n",
    "x_test, y_test, group_test = reshaped_features[test_idx], final_labels[test_idx], final_patient_ids[test_idx]\n",
    "\n",
    "(x_train.shape, y_train.shape, group_train.shape), (x_val.shape, y_val.shape, group_val.shape), (x_test.shape, y_test.shape, group_train.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 507,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using cache found in /Users/kat/.cache/torch/hub/OxWearables_ssl-wearables_main\n",
      "/Users/kat/.cache/torch/hub/OxWearables_ssl-wearables_main/hubconf.py:15: FutureWarning: You are using `torch.load` with `weights_only=False` (the current default value), which uses the default pickle module implicitly. It is possible to construct malicious pickle data which will execute arbitrary code during unpickling (See https://github.com/pytorch/pytorch/blob/main/SECURITY.md#untrusted-models for more details). In a future release, the default value for `weights_only` will be flipped to `True`. This limits the functions that could be executed during unpickling. Arbitrary objects will no longer be allowed to be loaded via this mode unless they are explicitly allowlisted by the user via `torch.serialization.add_safe_globals`. We recommend you start setting `weights_only=True` for any use case where you don't have full control of the loaded file. Please open an issue on GitHub for any issues related to this experimental feature.\n",
      "  pretrained_dict = torch.load(weight_path, map_location=my_device)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "131 Weights loaded\n",
      "training set sample count : 21635\n",
      "validation set sample count : 3593\n",
      "test set sample count : 3572\n"
     ]
    }
   ],
   "source": [
    "# construct dataloaders\n",
    "train_dataset = NormalDataset(x_train, y_train, group_train, name=\"training\", transform=True)\n",
    "val_dataset = NormalDataset(x_val, y_val, group_val, name=\"validation\")\n",
    "test_dataset = NormalDataset(x_test, y_test, group_test, name=\"test\")\n",
    "train_loader = DataLoader(\n",
    "    train_dataset,\n",
    "    batch_size=128,\n",
    "    shuffle=True,\n",
    "    num_workers=2,\n",
    ")\n",
    "val_loader = DataLoader(\n",
    "    val_dataset,\n",
    "    batch_size=128,\n",
    "    shuffle=False,\n",
    "    num_workers=0,\n",
    ")\n",
    "test_loader = DataLoader(\n",
    "    test_dataset,\n",
    "    batch_size=128,\n",
    "    shuffle=False,\n",
    "    num_workers=0,\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 509,
   "metadata": {},
   "outputs": [],
   "source": [
    "def train_harnet10(model, train_loader, val_loader, device, weights=None):\n",
    "    state_dict = 'state_dict.pt'\n",
    "    num_epoch = 100\n",
    "    optimizer = torch.optim.Adam(\n",
    "        model.parameters(), lr=0.0001, amsgrad=True\n",
    "    )\n",
    "    if weights:\n",
    "        weights = torch.FloatTensor(weights).to(device)\n",
    "        loss_fn = nn.CrossEntropyLoss(weight=weights)\n",
    "    else:\n",
    "        loss_fn = nn.CrossEntropyLoss()\n",
    "\n",
    "    early_stopping = EarlyStopping(\n",
    "        patience=5, path=state_dict, verbose=True\n",
    "    )\n",
    "\n",
    "    for epoch in range(num_epoch):\n",
    "        model.train()\n",
    "        train_losses = []\n",
    "        train_acces = []\n",
    "        for i, (x, y, _) in enumerate(tqdm(train_loader)):\n",
    "            x.requires_grad_(True)\n",
    "            x = x.to(device, dtype=torch.float)\n",
    "            true_y = y.to(device, dtype=torch.long)\n",
    "            print(f\"Shape of input to the model: {x.shape}\")\n",
    "            optimizer.zero_grad()\n",
    "            # # Forward pass\n",
    "            # try:\n",
    "            #     logits = model(x)\n",
    "            # except Exception as e:\n",
    "            #     print(f\"Error during forward pass: {e}\")\n",
    "            #     return  # Stop execution if an error occurs\n",
    "            x = torch.nn.functional.pad(x, (0, 128))  # Pad sequence length dimension from 10 to 128\n",
    "            \n",
    "            logits = model(x)\n",
    "            loss = loss_fn(logits, true_y)\n",
    "            loss.backward()\n",
    "            optimizer.step()\n",
    "\n",
    "            pred_y = torch.argmax(logits, dim=1)\n",
    "            train_acc = torch.sum(pred_y == true_y)\n",
    "            train_acc = train_acc / (pred_y.size()[0])\n",
    "\n",
    "            train_losses.append(loss.cpu().detach())\n",
    "            train_acces.append(train_acc.cpu().detach())\n",
    "\n",
    "        val_loss, val_acc = _validate_model(model, val_loader, device, loss_fn)\n",
    "\n",
    "        epoch_len = len(str(num_epoch))\n",
    "        print_msg = (\n",
    "            f\"[{epoch:>{epoch_len}}/{num_epoch:>{epoch_len}}] | \"\n",
    "            + f\"train_loss: {np.mean(train_losses):.3f} | \"\n",
    "            + f\"train_acc: {np.mean(train_acces):.3f} | \"\n",
    "            + f\"val_loss: {val_loss:.3f} | \"\n",
    "            + f\"val_acc: {val_acc:.2f}\"\n",
    "        )\n",
    "\n",
    "        early_stopping(val_loss, model)\n",
    "        print(print_msg)\n",
    "\n",
    "        if early_stopping.early_stop:\n",
    "            print('Early stopping')\n",
    "            print(f'SSLNet weights saved to {state_dict}')\n",
    "            break"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 511,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Inverse class weights: \n",
      "[1.0]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  0%|                                                   | 0/170 [00:00<?, ?it/s]python(51599) MallocStackLogging: can't turn off malloc stack logging because it was not enabled.\n",
      "python(51601) MallocStackLogging: can't turn off malloc stack logging because it was not enabled.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Shape of input to the model: torch.Size([128, 3, 10])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  0%|                                                   | 0/170 [00:04<?, ?it/s]\n"
     ]
    },
    {
     "ename": "RuntimeError",
     "evalue": "Calculated padded input size per channel: (7). Kernel size: (9). Kernel size can't be greater than actual input size",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mRuntimeError\u001b[0m                              Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[511], line 2\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[38;5;66;03m# Train the model. The trained weights will be saved in the file 'state_dict.pt'\u001b[39;00m\n\u001b[0;32m----> 2\u001b[0m train(sslnet, train_loader, val_loader, device, get_inverse_class_weights(y_train))\n",
      "Cell \u001b[0;32mIn[509], line 52\u001b[0m, in \u001b[0;36mtrain\u001b[0;34m(model, train_loader, val_loader, device, weights)\u001b[0m\n\u001b[1;32m     44\u001b[0m \u001b[38;5;66;03m# # Forward pass\u001b[39;00m\n\u001b[1;32m     45\u001b[0m \u001b[38;5;66;03m# try:\u001b[39;00m\n\u001b[1;32m     46\u001b[0m \u001b[38;5;66;03m#     logits = model(x)\u001b[39;00m\n\u001b[1;32m     47\u001b[0m \u001b[38;5;66;03m# except Exception as e:\u001b[39;00m\n\u001b[1;32m     48\u001b[0m \u001b[38;5;66;03m#     print(f\"Error during forward pass: {e}\")\u001b[39;00m\n\u001b[1;32m     49\u001b[0m \u001b[38;5;66;03m#     return  # Stop execution if an error occurs\u001b[39;00m\n\u001b[1;32m     50\u001b[0m x \u001b[38;5;241m=\u001b[39m torch\u001b[38;5;241m.\u001b[39mnn\u001b[38;5;241m.\u001b[39mfunctional\u001b[38;5;241m.\u001b[39mpad(x, (\u001b[38;5;241m0\u001b[39m, \u001b[38;5;241m128\u001b[39m))  \u001b[38;5;66;03m# Pad sequence length dimension from 10 to 128\u001b[39;00m\n\u001b[0;32m---> 52\u001b[0m logits \u001b[38;5;241m=\u001b[39m model(x)\n\u001b[1;32m     53\u001b[0m \u001b[38;5;28mprint\u001b[39m(logits)\n\u001b[1;32m     54\u001b[0m loss \u001b[38;5;241m=\u001b[39m loss_fn(logits, true_y)\n",
      "File \u001b[0;32m/Applications/anaconda3/lib/python3.12/site-packages/torch/nn/modules/module.py:1736\u001b[0m, in \u001b[0;36mModule._wrapped_call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1734\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_compiled_call_impl(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)  \u001b[38;5;66;03m# type: ignore[misc]\u001b[39;00m\n\u001b[1;32m   1735\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m-> 1736\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_call_impl(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)\n",
      "File \u001b[0;32m/Applications/anaconda3/lib/python3.12/site-packages/torch/nn/modules/module.py:1747\u001b[0m, in \u001b[0;36mModule._call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1742\u001b[0m \u001b[38;5;66;03m# If we don't have any hooks, we want to skip the rest of the logic in\u001b[39;00m\n\u001b[1;32m   1743\u001b[0m \u001b[38;5;66;03m# this function, and just call forward.\u001b[39;00m\n\u001b[1;32m   1744\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m (\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_pre_hooks\n\u001b[1;32m   1745\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_backward_hooks\n\u001b[1;32m   1746\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_forward_pre_hooks):\n\u001b[0;32m-> 1747\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m forward_call(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)\n\u001b[1;32m   1749\u001b[0m result \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[1;32m   1750\u001b[0m called_always_called_hooks \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mset\u001b[39m()\n",
      "File \u001b[0;32m~/.cache/torch/hub/OxWearables_ssl-wearables_main/sslearning/models/accNet.py:836\u001b[0m, in \u001b[0;36mResnet.forward\u001b[0;34m(self, x)\u001b[0m\n\u001b[1;32m    835\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mforward\u001b[39m(\u001b[38;5;28mself\u001b[39m, x):\n\u001b[0;32m--> 836\u001b[0m     feats \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mfeature_extractor(x)\n\u001b[1;32m    838\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mis_mtl:\n\u001b[1;32m    839\u001b[0m         aot_y \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39maot_h(feats\u001b[38;5;241m.\u001b[39mview(x\u001b[38;5;241m.\u001b[39mshape[\u001b[38;5;241m0\u001b[39m], \u001b[38;5;241m-\u001b[39m\u001b[38;5;241m1\u001b[39m))\n",
      "File \u001b[0;32m/Applications/anaconda3/lib/python3.12/site-packages/torch/nn/modules/module.py:1736\u001b[0m, in \u001b[0;36mModule._wrapped_call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1734\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_compiled_call_impl(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)  \u001b[38;5;66;03m# type: ignore[misc]\u001b[39;00m\n\u001b[1;32m   1735\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m-> 1736\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_call_impl(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)\n",
      "File \u001b[0;32m/Applications/anaconda3/lib/python3.12/site-packages/torch/nn/modules/module.py:1747\u001b[0m, in \u001b[0;36mModule._call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1742\u001b[0m \u001b[38;5;66;03m# If we don't have any hooks, we want to skip the rest of the logic in\u001b[39;00m\n\u001b[1;32m   1743\u001b[0m \u001b[38;5;66;03m# this function, and just call forward.\u001b[39;00m\n\u001b[1;32m   1744\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m (\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_pre_hooks\n\u001b[1;32m   1745\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_backward_hooks\n\u001b[1;32m   1746\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_forward_pre_hooks):\n\u001b[0;32m-> 1747\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m forward_call(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)\n\u001b[1;32m   1749\u001b[0m result \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[1;32m   1750\u001b[0m called_always_called_hooks \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mset\u001b[39m()\n",
      "File \u001b[0;32m/Applications/anaconda3/lib/python3.12/site-packages/torch/nn/modules/container.py:250\u001b[0m, in \u001b[0;36mSequential.forward\u001b[0;34m(self, input)\u001b[0m\n\u001b[1;32m    248\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mforward\u001b[39m(\u001b[38;5;28mself\u001b[39m, \u001b[38;5;28minput\u001b[39m):\n\u001b[1;32m    249\u001b[0m     \u001b[38;5;28;01mfor\u001b[39;00m module \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mself\u001b[39m:\n\u001b[0;32m--> 250\u001b[0m         \u001b[38;5;28minput\u001b[39m \u001b[38;5;241m=\u001b[39m module(\u001b[38;5;28minput\u001b[39m)\n\u001b[1;32m    251\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28minput\u001b[39m\n",
      "File \u001b[0;32m/Applications/anaconda3/lib/python3.12/site-packages/torch/nn/modules/module.py:1736\u001b[0m, in \u001b[0;36mModule._wrapped_call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1734\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_compiled_call_impl(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)  \u001b[38;5;66;03m# type: ignore[misc]\u001b[39;00m\n\u001b[1;32m   1735\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m-> 1736\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_call_impl(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)\n",
      "File \u001b[0;32m/Applications/anaconda3/lib/python3.12/site-packages/torch/nn/modules/module.py:1747\u001b[0m, in \u001b[0;36mModule._call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1742\u001b[0m \u001b[38;5;66;03m# If we don't have any hooks, we want to skip the rest of the logic in\u001b[39;00m\n\u001b[1;32m   1743\u001b[0m \u001b[38;5;66;03m# this function, and just call forward.\u001b[39;00m\n\u001b[1;32m   1744\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m (\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_pre_hooks\n\u001b[1;32m   1745\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_backward_hooks\n\u001b[1;32m   1746\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_forward_pre_hooks):\n\u001b[0;32m-> 1747\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m forward_call(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)\n\u001b[1;32m   1749\u001b[0m result \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[1;32m   1750\u001b[0m called_always_called_hooks \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mset\u001b[39m()\n",
      "File \u001b[0;32m/Applications/anaconda3/lib/python3.12/site-packages/torch/nn/modules/container.py:250\u001b[0m, in \u001b[0;36mSequential.forward\u001b[0;34m(self, input)\u001b[0m\n\u001b[1;32m    248\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mforward\u001b[39m(\u001b[38;5;28mself\u001b[39m, \u001b[38;5;28minput\u001b[39m):\n\u001b[1;32m    249\u001b[0m     \u001b[38;5;28;01mfor\u001b[39;00m module \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mself\u001b[39m:\n\u001b[0;32m--> 250\u001b[0m         \u001b[38;5;28minput\u001b[39m \u001b[38;5;241m=\u001b[39m module(\u001b[38;5;28minput\u001b[39m)\n\u001b[1;32m    251\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28minput\u001b[39m\n",
      "File \u001b[0;32m/Applications/anaconda3/lib/python3.12/site-packages/torch/nn/modules/module.py:1736\u001b[0m, in \u001b[0;36mModule._wrapped_call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1734\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_compiled_call_impl(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)  \u001b[38;5;66;03m# type: ignore[misc]\u001b[39;00m\n\u001b[1;32m   1735\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m-> 1736\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_call_impl(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)\n",
      "File \u001b[0;32m/Applications/anaconda3/lib/python3.12/site-packages/torch/nn/modules/module.py:1747\u001b[0m, in \u001b[0;36mModule._call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1742\u001b[0m \u001b[38;5;66;03m# If we don't have any hooks, we want to skip the rest of the logic in\u001b[39;00m\n\u001b[1;32m   1743\u001b[0m \u001b[38;5;66;03m# this function, and just call forward.\u001b[39;00m\n\u001b[1;32m   1744\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m (\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_pre_hooks\n\u001b[1;32m   1745\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_backward_hooks\n\u001b[1;32m   1746\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_forward_pre_hooks):\n\u001b[0;32m-> 1747\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m forward_call(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)\n\u001b[1;32m   1749\u001b[0m result \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[1;32m   1750\u001b[0m called_always_called_hooks \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mset\u001b[39m()\n",
      "File \u001b[0;32m~/.cache/torch/hub/OxWearables_ssl-wearables_main/sslearning/models/accNet.py:591\u001b[0m, in \u001b[0;36mDownsample.forward\u001b[0;34m(self, x)\u001b[0m\n\u001b[1;32m    590\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mforward\u001b[39m(\u001b[38;5;28mself\u001b[39m, x):\n\u001b[0;32m--> 591\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m F\u001b[38;5;241m.\u001b[39mconv1d(\n\u001b[1;32m    592\u001b[0m         x,\n\u001b[1;32m    593\u001b[0m         \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mkernel,\n\u001b[1;32m    594\u001b[0m         stride\u001b[38;5;241m=\u001b[39m\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mstride,\n\u001b[1;32m    595\u001b[0m         padding\u001b[38;5;241m=\u001b[39m\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mpadding,\n\u001b[1;32m    596\u001b[0m         groups\u001b[38;5;241m=\u001b[39mx\u001b[38;5;241m.\u001b[39mshape[\u001b[38;5;241m1\u001b[39m],\n\u001b[1;32m    597\u001b[0m     )\n",
      "\u001b[0;31mRuntimeError\u001b[0m: Calculated padded input size per channel: (7). Kernel size: (9). Kernel size can't be greater than actual input size"
     ]
    }
   ],
   "source": [
    "# Train the model. The trained weights will be saved in the file 'state_dict.pt'\n",
    "train_harnet10(sslnet, train_loader, val_loader, device, get_inverse_class_weights(y_train))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 449,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using cache found in /Users/kat/.cache/torch/hub/OxWearables_ssl-wearables_main\n",
      "/Users/kat/.cache/torch/hub/OxWearables_ssl-wearables_main/hubconf.py:15: FutureWarning: You are using `torch.load` with `weights_only=False` (the current default value), which uses the default pickle module implicitly. It is possible to construct malicious pickle data which will execute arbitrary code during unpickling (See https://github.com/pytorch/pytorch/blob/main/SECURITY.md#untrusted-models for more details). In a future release, the default value for `weights_only` will be flipped to `True`. This limits the functions that could be executed during unpickling. Arbitrary objects will no longer be allowed to be loaded via this mode unless they are explicitly allowlisted by the user via `torch.serialization.add_safe_globals`. We recommend you start setting `weights_only=True` for any use case where you don't have full control of the loaded file. Please open an issue on GitHub for any issues related to this experimental feature.\n",
      "  pretrained_dict = torch.load(weight_path, map_location=my_device)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "131 Weights loaded\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "Resnet(\n",
       "  (feature_extractor): Sequential(\n",
       "    (layer1): Sequential(\n",
       "      (0): Conv1d(3, 64, kernel_size=(5,), stride=(1,), padding=(2,), bias=False, padding_mode=circular)\n",
       "      (1): ResBlock(\n",
       "        (bn1): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (bn2): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (conv1): Conv1d(64, 64, kernel_size=(5,), stride=(1,), padding=(2,), bias=False, padding_mode=circular)\n",
       "        (conv2): Conv1d(64, 64, kernel_size=(5,), stride=(1,), padding=(2,), bias=False, padding_mode=circular)\n",
       "        (relu): ReLU(inplace=True)\n",
       "      )\n",
       "      (2): ResBlock(\n",
       "        (bn1): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (bn2): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (conv1): Conv1d(64, 64, kernel_size=(5,), stride=(1,), padding=(2,), bias=False, padding_mode=circular)\n",
       "        (conv2): Conv1d(64, 64, kernel_size=(5,), stride=(1,), padding=(2,), bias=False, padding_mode=circular)\n",
       "        (relu): ReLU(inplace=True)\n",
       "      )\n",
       "      (3): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (4): ReLU(inplace=True)\n",
       "      (5): Downsample()\n",
       "    )\n",
       "    (layer2): Sequential(\n",
       "      (0): Conv1d(64, 128, kernel_size=(5,), stride=(1,), padding=(2,), bias=False, padding_mode=circular)\n",
       "      (1): ResBlock(\n",
       "        (bn1): BatchNorm1d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (bn2): BatchNorm1d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (conv1): Conv1d(128, 128, kernel_size=(5,), stride=(1,), padding=(2,), bias=False, padding_mode=circular)\n",
       "        (conv2): Conv1d(128, 128, kernel_size=(5,), stride=(1,), padding=(2,), bias=False, padding_mode=circular)\n",
       "        (relu): ReLU(inplace=True)\n",
       "      )\n",
       "      (2): ResBlock(\n",
       "        (bn1): BatchNorm1d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (bn2): BatchNorm1d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (conv1): Conv1d(128, 128, kernel_size=(5,), stride=(1,), padding=(2,), bias=False, padding_mode=circular)\n",
       "        (conv2): Conv1d(128, 128, kernel_size=(5,), stride=(1,), padding=(2,), bias=False, padding_mode=circular)\n",
       "        (relu): ReLU(inplace=True)\n",
       "      )\n",
       "      (3): BatchNorm1d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (4): ReLU(inplace=True)\n",
       "      (5): Downsample()\n",
       "    )\n",
       "    (layer3): Sequential(\n",
       "      (0): Conv1d(128, 256, kernel_size=(5,), stride=(1,), padding=(2,), bias=False, padding_mode=circular)\n",
       "      (1): ResBlock(\n",
       "        (bn1): BatchNorm1d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (bn2): BatchNorm1d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (conv1): Conv1d(256, 256, kernel_size=(5,), stride=(1,), padding=(2,), bias=False, padding_mode=circular)\n",
       "        (conv2): Conv1d(256, 256, kernel_size=(5,), stride=(1,), padding=(2,), bias=False, padding_mode=circular)\n",
       "        (relu): ReLU(inplace=True)\n",
       "      )\n",
       "      (2): ResBlock(\n",
       "        (bn1): BatchNorm1d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (bn2): BatchNorm1d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (conv1): Conv1d(256, 256, kernel_size=(5,), stride=(1,), padding=(2,), bias=False, padding_mode=circular)\n",
       "        (conv2): Conv1d(256, 256, kernel_size=(5,), stride=(1,), padding=(2,), bias=False, padding_mode=circular)\n",
       "        (relu): ReLU(inplace=True)\n",
       "      )\n",
       "      (3): BatchNorm1d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (4): ReLU(inplace=True)\n",
       "      (5): Downsample()\n",
       "    )\n",
       "    (layer4): Sequential(\n",
       "      (0): Conv1d(256, 512, kernel_size=(5,), stride=(1,), padding=(2,), bias=False, padding_mode=circular)\n",
       "      (1): ResBlock(\n",
       "        (bn1): BatchNorm1d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (bn2): BatchNorm1d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (conv1): Conv1d(512, 512, kernel_size=(5,), stride=(1,), padding=(2,), bias=False, padding_mode=circular)\n",
       "        (conv2): Conv1d(512, 512, kernel_size=(5,), stride=(1,), padding=(2,), bias=False, padding_mode=circular)\n",
       "        (relu): ReLU(inplace=True)\n",
       "      )\n",
       "      (2): ResBlock(\n",
       "        (bn1): BatchNorm1d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (bn2): BatchNorm1d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (conv1): Conv1d(512, 512, kernel_size=(5,), stride=(1,), padding=(2,), bias=False, padding_mode=circular)\n",
       "        (conv2): Conv1d(512, 512, kernel_size=(5,), stride=(1,), padding=(2,), bias=False, padding_mode=circular)\n",
       "        (relu): ReLU(inplace=True)\n",
       "      )\n",
       "      (3): BatchNorm1d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (4): ReLU(inplace=True)\n",
       "      (5): Downsample()\n",
       "    )\n",
       "    (layer5): Sequential(\n",
       "      (0): Conv1d(512, 1024, kernel_size=(5,), stride=(1,), padding=(2,), bias=False, padding_mode=circular)\n",
       "      (1): BatchNorm1d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (2): ReLU(inplace=True)\n",
       "      (3): Downsample()\n",
       "    )\n",
       "  )\n",
       "  (classifier): EvaClassifier(\n",
       "    (linear1): Linear(in_features=1024, out_features=512, bias=True)\n",
       "    (linear2): Linear(in_features=512, out_features=2, bias=True)\n",
       "  )\n",
       ")"
      ]
     },
     "execution_count": 449,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Explore error\n",
    "sslnet: nn.Module = torch.hub.load(repo, 'harnet10', trust_repo=True, class_num=2, pretrained=True, weights_only=False)\n",
    "sslnet.to(device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 405,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using cache found in /Users/kat/.cache/torch/hub/OxWearables_ssl-wearables_main\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "131 Weights loaded\n",
      "training set sample count : 35999\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/kat/.cache/torch/hub/OxWearables_ssl-wearables_main/hubconf.py:15: FutureWarning: You are using `torch.load` with `weights_only=False` (the current default value), which uses the default pickle module implicitly. It is possible to construct malicious pickle data which will execute arbitrary code during unpickling (See https://github.com/pytorch/pytorch/blob/main/SECURITY.md#untrusted-models for more details). In a future release, the default value for `weights_only` will be flipped to `True`. This limits the functions that could be executed during unpickling. Arbitrary objects will no longer be allowed to be loaded via this mode unless they are explicitly allowlisted by the user via `torch.serialization.add_safe_globals`. We recommend you start setting `weights_only=True` for any use case where you don't have full control of the loaded file. Please open an issue on GitHub for any issues related to this experimental feature.\n",
      "  pretrained_dict = torch.load(weight_path, map_location=my_device)\n"
     ]
    }
   ],
   "source": [
    "# Editing data type to match Pytorch\n",
    "X = data[['x','y','z']].values.astype(\n",
    "    \"f4\"\n",
    ")  # PyTorch defaults to float32\n",
    "Y=data['annotation'].values\n",
    "time=time_params(data)[2].values\n",
    "reps=round(len(data)/10)\n",
    "pids=[]\n",
    "for x in range(1,11):\n",
    "    pids+=[x]*reps\n",
    "group_train=pids[:len(data)]\n",
    "\n",
    "# construct dataloaders\n",
    "train_dataset = NormalDataset(X, Y, group_train, name=\"training\", transform=True)\n",
    "val_dataset = NormalDataset(x_val, y_val, group_val, name=\"validation\")\n",
    "test_dataset = NormalDataset(x_test, y_test, group_test, name=\"test\")\n",
    "\n",
    "train_loader = DataLoader(\n",
    "    train_dataset,\n",
    "    batch_size=128,\n",
    "    shuffle=True#\n",
    ")\n",
    "\n",
    "val_loader = DataLoader(\n",
    "    val_dataset,\n",
    "    batch_size=128,\n",
    "    shuffle=False\n",
    ")\n",
    "\n",
    "test_loader = DataLoader(\n",
    "    test_dataset,\n",
    "    batch_size=128,\n",
    "    shuffle=False\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 263,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>timestamp</th>\n",
       "      <th>x</th>\n",
       "      <th>y</th>\n",
       "      <th>z</th>\n",
       "      <th>annotation</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>2019-07-22 13:32:52.809</td>\n",
       "      <td>0.411490</td>\n",
       "      <td>0.181621</td>\n",
       "      <td>-0.497670</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2019-07-22 13:32:52.819</td>\n",
       "      <td>0.688887</td>\n",
       "      <td>0.124579</td>\n",
       "      <td>-0.506827</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2019-07-22 13:32:52.828</td>\n",
       "      <td>0.736904</td>\n",
       "      <td>0.020060</td>\n",
       "      <td>-0.306294</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>2019-07-22 13:32:52.838</td>\n",
       "      <td>0.777280</td>\n",
       "      <td>-0.050111</td>\n",
       "      <td>-0.225117</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>2019-07-22 13:32:52.848</td>\n",
       "      <td>0.869990</td>\n",
       "      <td>-0.073111</td>\n",
       "      <td>-0.216985</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>359994</th>\n",
       "      <td>2019-07-22 14:32:52.750</td>\n",
       "      <td>0.880580</td>\n",
       "      <td>0.247766</td>\n",
       "      <td>-0.419820</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>359995</th>\n",
       "      <td>2019-07-22 14:32:52.759</td>\n",
       "      <td>0.880580</td>\n",
       "      <td>0.247766</td>\n",
       "      <td>-0.419820</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>359996</th>\n",
       "      <td>2019-07-22 14:32:52.769</td>\n",
       "      <td>0.882499</td>\n",
       "      <td>0.247766</td>\n",
       "      <td>-0.419820</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>359997</th>\n",
       "      <td>2019-07-22 14:32:52.779</td>\n",
       "      <td>0.865828</td>\n",
       "      <td>0.247766</td>\n",
       "      <td>-0.419820</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>359998</th>\n",
       "      <td>2019-07-22 14:32:52.789</td>\n",
       "      <td>0.875269</td>\n",
       "      <td>0.247766</td>\n",
       "      <td>-0.419820</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>359999 rows × 5 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                     timestamp         x         y         z  annotation\n",
       "0      2019-07-22 13:32:52.809  0.411490  0.181621 -0.497670           0\n",
       "1      2019-07-22 13:32:52.819  0.688887  0.124579 -0.506827           0\n",
       "2      2019-07-22 13:32:52.828  0.736904  0.020060 -0.306294           0\n",
       "3      2019-07-22 13:32:52.838  0.777280 -0.050111 -0.225117           0\n",
       "4      2019-07-22 13:32:52.848  0.869990 -0.073111 -0.216985           0\n",
       "...                        ...       ...       ...       ...         ...\n",
       "359994 2019-07-22 14:32:52.750  0.880580  0.247766 -0.419820           0\n",
       "359995 2019-07-22 14:32:52.759  0.880580  0.247766 -0.419820           0\n",
       "359996 2019-07-22 14:32:52.769  0.882499  0.247766 -0.419820           0\n",
       "359997 2019-07-22 14:32:52.779  0.865828  0.247766 -0.419820           0\n",
       "359998 2019-07-22 14:32:52.789  0.875269  0.247766 -0.419820           0\n",
       "\n",
       "[359999 rows x 5 columns]"
      ]
     },
     "execution_count": 263,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 381,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[ 0.41149 ,  0.181621, -0.49767 ],\n",
       "       [ 0.688887,  0.124579, -0.506827],\n",
       "       [ 0.736904,  0.02006 , -0.306294],\n",
       "       ...,\n",
       "       [ 0.882499,  0.247766, -0.41982 ],\n",
       "       [ 0.865828,  0.247766, -0.41982 ],\n",
       "       [ 0.875269,  0.247766, -0.41982 ]], dtype=float32)"
      ]
     },
     "execution_count": 381,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 369,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "X shape: (359999, 3)\n",
      "Y shape: (359999,)\n",
      "Label distribution:\n",
      "0    359394\n",
      "1       605\n",
      "Name: count, dtype: int64\n",
      "Original labels: [0 1]\n",
      "Transformed labels: [0 1]\n"
     ]
    }
   ],
   "source": [
    "(\n",
    "    x_train, y_train, group_train, time_train,\n",
    "    x_val, y_val, group_val, time_val,\n",
    "    x_test, y_test, group_test, time_test,\n",
    "    le\n",
    ") = load_data()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 275,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using cache found in /Users/kat/.cache/torch/hub/OxWearables_ssl-wearables_main\n",
      "/Users/kat/.cache/torch/hub/OxWearables_ssl-wearables_main/hubconf.py:15: FutureWarning: You are using `torch.load` with `weights_only=False` (the current default value), which uses the default pickle module implicitly. It is possible to construct malicious pickle data which will execute arbitrary code during unpickling (See https://github.com/pytorch/pytorch/blob/main/SECURITY.md#untrusted-models for more details). In a future release, the default value for `weights_only` will be flipped to `True`. This limits the functions that could be executed during unpickling. Arbitrary objects will no longer be allowed to be loaded via this mode unless they are explicitly allowlisted by the user via `torch.serialization.add_safe_globals`. We recommend you start setting `weights_only=True` for any use case where you don't have full control of the loaded file. Please open an issue on GitHub for any issues related to this experimental feature.\n",
      "  pretrained_dict = torch.load(weight_path, map_location=my_device)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "131 Weights loaded\n",
      "training set sample count : 251999\n",
      "validation set sample count : 36000\n",
      "test set sample count : 72000\n"
     ]
    }
   ],
   "source": [
    "# Tranforming the data to have another dimension\n",
    "x_train = np.expand_dims(x_train, axis=1)\n",
    "y_train = np.expand_dims(y_train, axis=1)\n",
    "group_train = np.expand_dims(group_train, axis=1)\n",
    "x_val = np.expand_dims(x_val, axis=1)\n",
    "y_val = np.expand_dims(y_val, axis=1)\n",
    "group_val = np.expand_dims(group_val, axis=1)\n",
    "x_test = np.expand_dims(x_test, axis=1)\n",
    "y_test = np.expand_dims(y_test, axis=1)\n",
    "group_test = np.expand_dims(group_test, axis=1)\n",
    "\n",
    "# construct dataloaders\n",
    "train_dataset = NormalDataset(x_train, y_train, group_train, name=\"training\", transform=True)\n",
    "val_dataset = NormalDataset(x_val, y_val, group_val, name=\"validation\")\n",
    "test_dataset = NormalDataset(x_test, y_test, group_test, name=\"test\")\n",
    "\n",
    "train_loader = DataLoader(\n",
    "    train_dataset,\n",
    "    batch_size=128,\n",
    "    shuffle=True\n",
    ")\n",
    "val_loader = DataLoader(\n",
    "    val_dataset,\n",
    "    batch_size=128,\n",
    "    shuffle=False\n",
    ")\n",
    "test_loader = DataLoader(\n",
    "    test_dataset,\n",
    "    batch_size=128,\n",
    "    shuffle=False\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Successful model Harnet10 model:\n",
    "train_harnet10(sslnet, train_loader, val_loader, device, get_inverse_class_weights(y_train))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "# load fine tuned weights (best weights prior to early-stopping) do inference on the test set\n",
    "model_dict = torch.load('state_dict.pt', map_location=device)\n",
    "sslnet.load_state_dict(model_dict)\n",
    "y_test, y_test_pred, pid_test = predict(sslnet, test_loader, device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "scores = classification_scores(y_test, y_test_pred)\n",
    "print(scores.round(3))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "## 2. Fine-tuning Prospects "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "### Freezing all the conv layers but the linear layers "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "for name, param in sslnet.named_parameters():\n",
    "    print(name)\n",
    "    \n",
    "def set_bn_eval(m):\n",
    "    classname = m.__class__.__name__\n",
    "    if classname.find(\"BatchNorm1d\") != -1:\n",
    "        m.eval()\n",
    "\n",
    "i = 0\n",
    "name_idx = 0\n",
    "for name, param in sslnet.named_parameters():\n",
    "    if name.split(\".\")[name_idx] == \"feature_extractor\":\n",
    "        param.requires_grad = False\n",
    "        i += 1\n",
    "sslnet.apply(set_bn_eval)\n",
    "\n",
    "print(\"Frozen weights: %d\" % i)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "### Freezing all the weights layers in the first residual block"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "i = 0\n",
    "name_idx = 1\n",
    "for name, param in sslnet.named_parameters():\n",
    "    if name.split(\".\")[name_idx] == \"layer1\":\n",
    "        param.requires_grad = False\n",
    "        i += 1\n",
    "sslnet.apply(set_bn_eval)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.4"
  },
  "vscode": {
   "interpreter": {
    "hash": "1224fc7bbcf00895b4029033e99b6a45061f4970375018967a2862735a536e29"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
